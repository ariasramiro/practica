{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariasramiro/practica/blob/master/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tW9D-RFVUJMi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduccion a Pytorch\n",
        "\n",
        "Pytorch es una libreria que permite trabajar con vectores y matrices de muchas dimensiones.\n",
        "\n",
        "En ese sentido es muy parecido a Numpy. En numpy a los vectores son llamados arrays. En pytorch se los llama tensores."
      ],
      "metadata": {
        "id": "aym_yfMPUE70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bPHectQTVUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1635cc6-5f03-41f3-8a84-ccbed078bba2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.,  6.],\n",
              "        [ 9., 12.],\n",
              "        [ 1.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = torch.tensor([[3.,6.],[9.,12.], [1.,2.]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BoN4tYvUZS8",
        "outputId": "4d76612a-42d9-45f9-9016-0fa9a7f77f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El shape del tensor es una lista del tamano de cada dimension. Si trabajamos con matrices (como comumnmente se llama a los vectores 2D), cada \"fila\" tiene la misma longitud: no hay una fila mas corta que otra.\n",
        "\n",
        "Lo mismo vale para mas dimensiones. No podemos hacer:"
      ],
      "metadata": {
        "id": "LlF7_o5JUemX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1., 2.], [3., 4.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "CmcWDnDxUd4Y",
        "outputId": "a74969c1-a18e-48cb-a96a-54c2ac4aa298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 1 (got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-50bc8b394db2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El `ValueError` se debe a que las longitudes de las filas `[1., 2.]` y `[3]` no coinciden."
      ],
      "metadata": {
        "id": "I-brPNgUkOnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensores con Pytorch\n",
        "\n",
        "Un tensor es un concepto matem谩tico que generaliza escalares, vectores y matrices hacia dimensiones superiores. Para ilustrarlo, un tensor de orden 0 se reduce a un escalar, mientras que un tensor de orden 1 se convierte en un vector. Cuando llegamos a una matriz de dos dimensiones, estamos ante un tensor de orden 2, y as铆 sucesivamente hasta llegar a n dimensiones. Los tensores tienen una amplia aplicaci贸n en distintos 谩mbitos, desde las matem谩ticas y la f铆sica hasta la inform谩tica y el aprendizaje autom谩tico.\n",
        "\n",
        "En el contexto del aprendizaje autom谩tico y el aprendizaje profundo, los tensores son la base de datos fundamental que representa las entradas, salidas y el estado interno de una red neuronal.\n",
        "\n",
        "PyTorch, en su esencia, es una biblioteca especializada en el procesamiento de tensores. Ofrece una amplia variedad de funciones altamente optimizadas para operar eficientemente con estos objetos, incluyendo operaciones cruciales como multiplicaciones de matrices y convoluciones. Adem谩s, PyTorch se integra sin problemas con aceleradores de hardware como las GPU, lo que puede impulsar de manera significativa los c谩lculos necesarios en el aprendizaje profundo. Esta capacidad de PyTorch para trabajar con tensores y aprovechar al m谩ximo el hardware subyacente lo convierte en una herramienta fundamental en el campo del aprendizaje autom谩tico y la inteligencia artificial."
      ],
      "metadata": {
        "id": "PjNGojrXiPTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creaci贸n de tensores\n",
        "\n",
        "A continuaci贸n varios ejemplos de c贸mo crear tensores en con Pytorch.\n"
      ],
      "metadata": {
        "id": "upA5fP3kixzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Escalares**"
      ],
      "metadata": {
        "id": "oySL--O1i1Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalares en PyTorch (tensor de orden 0)\n",
        "t1 = torch.tensor(4.)\n",
        "print(t1)\n",
        "print(\"Orden del tensor:\", t1.dim())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvR4lzlJiWOP",
        "outputId": "15b468a0-eb1a-4444-9eff-de3c51ce1c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "Orden del tensor: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`4.` es una abreviatura de `4.0.` Se emplea para indicar a Python (y PyTorch) que se desea crear un n煤mero en formato de coma flotante (`float`). Esto se puede verificar al revisar el atributo `dtype` de nuestro tensor."
      ],
      "metadata": {
        "id": "E7kW_enPi-n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipo de dato de un tensor\n",
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEN0nKHNjIIT",
        "outputId": "a9be5f99-8f7e-4c3b-a416-7a26fdbaca4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectores**"
      ],
      "metadata": {
        "id": "bO0YykB3jLXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector de 1 dimensi贸n (tensor de orden 1)\n",
        "t2 = torch.tensor([1, 2, 3, 4])\n",
        "print(t2)\n",
        "print(f\"Orden del tensor: {t2.ndim}\")\n",
        "print(f\"Forma del tensor: {t2.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfs0T-WDjLMP",
        "outputId": "12e76b0b-d277-43bd-8356-ce60cdd60805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos los elementos de un tensor tienen el mismo tipo. Por esta raz贸n, al crear un tensor que combina valores `float` y valores `int`, el tensor resultante adquiere el tipo `float`."
      ],
      "metadata": {
        "id": "K6dtecFljRra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2_mix = torch.tensor([1.0, 2, 3, 4])\n",
        "print(t2_mix)\n",
        "print(f\"Orden del tensor: {t2_mix.ndim}\")\n",
        "print(f\"Forma del tensor: {t2_mix.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t2_mix.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30DCRCqjXTE",
        "outputId": "190c17a5-6614-4175-b76f-819a218a31fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n",
            "Orden del tensor: 1\n",
            "Forma del tensor: torch.Size([4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matrices**"
      ],
      "metadata": {
        "id": "YhXrl-8cjaND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrices\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "print(t3)\n",
        "print(f\"Orden del tensor: {t3.ndim}\")\n",
        "print(f\"Forma del tensor: {t3.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {t3.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZIu_s6hjzgR",
        "outputId": "dc054e7b-bde6-4c57-d431-a0021dfb16c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 2])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de 3 dimensiones**\n",
        "\n"
      ],
      "metadata": {
        "id": "mS3vWxL1j39c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor tridimensional\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [13, 14, 15, 10]],\n",
        "    [[15, 16, 17, 10],\n",
        "     [11, 12, 13, 10],\n",
        "     [17, 18, 19., 10]]])"
      ],
      "metadata": {
        "id": "u4kg37Uyj6Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tensor de orden  **\n",
        "\n",
        "Los tensores pueden tener cualquier n煤mero de dimensiones y diferentes longitudes a lo largo de cada dimensi贸n. Se puede inspeccionar la longitud a lo largo de cada dimensi贸n usando el atributo `.shape`. Al igual que pasa con NumPy, no es posible crear tensores con una dimensionalidad incompatible."
      ],
      "metadata": {
        "id": "eX0kIBxskAdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generaci贸n de Tensores Aleatorios\n",
        "\n",
        "En el contexto de los modelos de aprendizaje autom谩tico, como las redes neuronales, se manipulan y buscan patrones dentro de los tensores. Por lo general, un modelo de aprendizaje autom谩tico comienza con tensores de n煤meros aleatorios (pesos y bias) que posteriormente se ajustan a medida que procesa los datos de entrenamiento y aprende de ellos.\n",
        "\n",
        "Para crear tensores con n煤meros aleatorios entre [0,1] se utiliza la funic贸n `torch.rand()` pasando el par谩metro `size`."
      ],
      "metadata": {
        "id": "bX_rMDZ4knkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor con valores aleatorios de dimensiones (3, 4)\n",
        "tensor_aleatorio = torch.rand(size=(3, 4))\n",
        "print(tensor_aleatorio)\n",
        "print(f\"Orden del tensor: {tensor_aleatorio.ndim}\")\n",
        "print(f\"Forma del tensor: {tensor_aleatorio.shape}\")\n",
        "print(f\"Tipo de dato del tensor: {tensor_aleatorio.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOHPuzsdkl1g",
        "outputId": "7fcb68c2-2f40-40c4-baba-42bc0cbb9ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6546, 0.8298, 0.5365, 0.5581],\n",
            "        [0.6686, 0.4676, 0.7414, 0.3003],\n",
            "        [0.2640, 0.9841, 0.5748, 0.3204]])\n",
            "Orden del tensor: 2\n",
            "Forma del tensor: torch.Size([3, 4])\n",
            "Tipo de dato del tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operaciones con tensores\n",
        "\n",
        "Para poder crear, entrenar y luego realizar predicciones con una red neuronal, es esencial llevar a cabo operaciones fundamentales entre tensores, que incluyen:\n",
        "\n",
        "*   Suma\n",
        "*   Resta\n",
        "*   Multiplicaci贸n (elemento a elemento)\n",
        "*   Divisi贸n\n",
        "*   Multiplicaci贸n de matrices"
      ],
      "metadata": {
        "id": "DqNJ-jCbk-fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suma\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZdR3x8elIoJ",
        "outputId": "3dfe3e85-74fc-40a0-893b-9c50ac7c10f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resta\n",
        "tensor = tensor - 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbFGY51mlOyj",
        "outputId": "7efc2ee5-cef0-4dc4-a61a-0315c50bf8ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci贸n por un escalar\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RydqtQ_4lLTT",
        "outputId": "06c1c068-fe14-40b9-f037-2b24f60e23b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-90, -80, -70])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiplicaci贸n de matrices\n",
        "\n",
        "\n",
        "La [multiplicaci贸n de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html) es una de las operaciones m谩s comunes en algoritmos de aprendizaje autom谩tico y aprendizaje profundo, como las redes neuronales. En PyTorch, esta funcionalidad se implementa a trav茅s del m茅todo torch.matmul(). Hay dos reglas principales a tener en cuenta al multiplicar matrices:\n",
        "\n",
        "\n",
        "\n",
        "1.   Las **dimensiones internas** deben coincidir:\n",
        "\n",
        "\n",
        "\n",
        "*   `(3, 2) @ (3, 2)` no es v谩lido\n",
        "*   `(2, 3) @ (3, 2)` es v谩lido\n",
        "*   `(3, 2) @ (2, 3)` es v谩lido\n",
        "\n",
        "\n",
        "2.   La matriz resultante tiene la forma de las **dimensiones externas**:\n",
        "*   `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "*   `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n"
      ],
      "metadata": {
        "id": "V5WY0Nn3lX8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante diferenciar entre la multiplicaci贸n elemento a elemento (element wise) y la multiplicaci贸n de matrices. Por ejemplo, para un `tensor` con valores `[1, 2, 3]`:\n",
        "\n",
        "| **Operaci贸n**                       | **C谩lculo**                                | **C贸digo**                |\n",
        "|------------------------------------|--------------------------------------------|---------------------------|\n",
        "| Multiplicaci贸n elemento a elemento | `[1*1, 2*2, 3*3] = [1, 4, 9]`               | `tensor * tensor`         |\n",
        "| Multiplicaci贸n de matrices         | `[1*1 + 2*2 + 3*3] = [14]`                  | `tensor.matmul(tensor)`   |\n"
      ],
      "metadata": {
        "id": "a0_zydYwmb-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])"
      ],
      "metadata": {
        "id": "pbNQRj70m9l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci贸n elemento a elemento de tensores\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmjA2pBom-Ui",
        "outputId": "bcf4d452-d1e5-4e51-bf42-c0f833e27b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci贸n matricial con el operador @\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ltH3EmnCP8",
        "outputId": "5cdba2f5-2516-40a8-c47f-5ee90c7c6383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicaci贸n matricial con el m茅todo matmul\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bGVQYEnnLgK",
        "outputId": "20912dda-0109-4b50-9b49-3925c334dde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C谩lculo del valor m谩ximo, m铆nimo, m茅dia y suma de un tensor"
      ],
      "metadata": {
        "id": "NRcBt0nSnRaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C谩lculo del valor m谩ximo, m铆nimo, m茅dia y suma de un tensor\n",
        "x = torch.tensor([1,2,1,3,1,2], dtype=torch.float32)  # para calcular la media hay que convertir a float\n",
        "print(f\"Min: {x.min()}\")\n",
        "print(f\"Max: {x.max()}\")\n",
        "print(f\"Media: {x.mean()}\")\n",
        "print(f\"Suma: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-yZV6QAnTo2",
        "outputId": "2e33244a-d225-484d-d239-d20a63389111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: 1.0\n",
            "Max: 3.0\n",
            "Media: 1.6666666269302368\n",
            "Suma: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ndices de los Valores M谩ximo y M铆nimo\n",
        "\n",
        "Es posible determinar el 铆ndice de un tensor donde se encuentra el valor m谩ximo o m铆nimo utilizando las funciones `torch.argmax()` y `torch.argmin()`. Esta operaci贸n resulta 煤til en situaciones en las que s贸lo se requiere conocer la posici贸n del valor m谩s alto (o m谩s bajo), y no el valor en s铆. Veremos un ejemplo de esto m谩s adelante cuando utilicemos la funci贸n de activaci贸n softmax."
      ],
      "metadata": {
        "id": "EWK2R-EVnYH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenci贸n del 铆ndice del valor m谩ximo y m铆nimo de un tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Se devuelve el 铆ndice del valor m谩ximo y m铆nimo\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoS-lN6OniAk",
        "outputId": "bed0a75f-ab49-47f8-c0ab-fe582b7fc2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Que introduce de nuevo pytorch sobre numpy\n",
        "Esencialmente dos cosas:\n",
        "\n",
        "*   Paralelizacion en GPU\n",
        "*   Calculo automatico de derivadas (gradiente)\n",
        "\n",
        "\n",
        "Estas funciones son muy deseables cuando trabajamos con redes neuronales. Aunque tambien hay librerias de, por ejemplo, algebra lineal que han aprovechado esto para ser escritas sobre pytorch y funcionar eficientemente.\n",
        "\n",
        "Pytorch tambien provee muchas de las funcionalidades necesarias para definir una red y entrenarla.\n",
        "\n",
        "Con la siguiente funcion podemos ver si tenemos una GPU disponible en nuestro sistema"
      ],
      "metadata": {
        "id": "-jtWib7iUs2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgDIhzrU7Ec",
        "outputId": "d90f6100-6107-4814-c35e-1df431329df1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos comparar la velocidad entre ejecutar algo en CPU o usando GPU (si tenemos).\n",
        "\n",
        "Pytorch requiere mover explicitamente los tensores a la GPU, se puede hacer facilmente mediante el metodo .cuda()\n",
        "\n",
        "(Si se operan vectores que estan en la GPU con vectores que estan en la GPU causara un error)"
      ],
      "metadata": {
        "id": "J3R1PzDRU-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)"
      ],
      "metadata": {
        "id": "t5pLuG51VDc1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znmJKPf3VFQo",
        "outputId": "50017d91-6ed7-4d8f-a0f3-2856bb840349"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.3 ms 卤 818 碌s per loop (mean 卤 std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.rand(1000,1000)\n",
        "B = torch.rand(1000,1000)\n",
        "if torch.cuda.is_available():\n",
        "    A = A.cuda()\n",
        "    B = B.cuda()\n",
        "    print(\"CUDA available\")\n",
        "else:\n",
        "    print(\"CUDA not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8t6P_C9VJRD",
        "outputId": "a97a9a9c-7b9c-403a-92ad-cbc552c535a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTKSs_xmVcv6",
        "outputId": "b5b115ec-f532-42b4-a153-347e2f3ef873"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "528 碌s 卤 20 碌s per loop (mean 卤 std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si ten茅s iOS (Mac) pod茅s ver como acelerar Pytorch con el backedn MPS (solo disponible para AMD o Sillicon Chip, NO Intel)."
      ],
      "metadata": {
        "id": "J2kVhf7RVk13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    print(\"MPS available\")\n",
        "    A = A.to(mps_device)\n",
        "    B = B.to(mps_device)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AmS8iM-VkM8",
        "outputId": "c76de7f4-3ec8-4752-dcde-b2b1e24ae0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS device not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuJ1oyDvVsqd",
        "outputId": "0045e3e2-ec99-4bf5-95dc-8d4f9fa66ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "575 碌s 卤 15.6 碌s per loop (mean 卤 std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd\n",
        "\n",
        "Autograd es una biblioteca de PyTorch que implementa la diferenciaci贸n autom谩tica. Utiliza la estructura gr谩fica para calcular gradientes y permite que el modelo aprenda actualizando sus par谩metros durante el entrenamiento. Autograd tambi茅n permite calcular gradientes con respecto a valores escalares arbitrarios, lo cual resulta 煤til para tareas como la optimizaci贸n.\n",
        "\n",
        "Es necesaria la instalacion de complementos en el sistema operativo y de la libreria `torchviz`"
      ],
      "metadata": {
        "id": "yCufW9M0cXrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "fD_vlsVLXXzs",
        "outputId": "bf073fca-84e6-4a73-9f6b-00db5bf868ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Creamos un tensor y asignamos el valor 7\n",
        "# seteamos requires_grad=True\n",
        "# Entonces, autograd registrar谩 las operaciones\n",
        "x=torch.tensor(7.0,requires_grad=True)\n",
        "\n",
        "# Definimos la funcion\n",
        "f = (x**2)+3\n",
        "\n",
        "# Diferencial usando torch\n",
        "# Utiliza la funcion inversa para calcualr el valor del gradiente\n",
        "f.backward()\n",
        "\n",
        "# Imprimimos el valor de la derivada de \"y\"\n",
        "# es decir, dy/dx = 2x  = 2 X 7.0 = 14.\n",
        "print(x.grad)\n",
        "\n",
        "# Imprimimos el grafo computacional\n",
        "make_dot(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1yrWTSyVYXgC",
        "outputId": "39702402-f904-4c8e-a3ca-d1a25b1ede94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n<!-- 133855790116752 -->\n<g id=\"node1\" class=\"node\">\n<title>133855790116752</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 133855790451296 -->\n<g id=\"node2\" class=\"node\">\n<title>133855790451296</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133855790451296&#45;&gt;133855790116752 -->\n<g id=\"edge4\" class=\"edge\">\n<title>133855790451296&#45;&gt;133855790116752</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 133855790451152 -->\n<g id=\"node3\" class=\"node\">\n<title>133855790451152</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 133855790451152&#45;&gt;133855790451296 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133855790451152&#45;&gt;133855790451296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 133855790449136 -->\n<g id=\"node4\" class=\"node\">\n<title>133855790449136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133855790449136&#45;&gt;133855790451152 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133855790449136&#45;&gt;133855790451152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n</g>\n<!-- 133855790116560 -->\n<g id=\"node5\" class=\"node\">\n<title>133855790116560</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 133855790116560&#45;&gt;133855790449136 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133855790116560&#45;&gt;133855790449136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79beb4cecb50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Creamos un tensor y asignamos el valor 7\n",
        "# seteamos requires_grad=True\n",
        "# Entonces, autograd registrar谩 las operaciones\n",
        "x=torch.tensor(7.0)\n",
        "\n",
        "# Definimos la funcion\n",
        "f = (x**2)+3\n",
        "\n",
        "# Diferencial usando torch\n",
        "# Utiliza la funcion inversa para calcualr el valor del gradiente\n",
        "f.backward()\n",
        "\n",
        "# Imprimimos el valor de la derivada de \"y\"\n",
        "# es decir, dy/dx = 2x  = 2 X 7.0 = 14.\n",
        "print(x.grad)\n",
        "\n",
        "# Imprimimos el grafo computacional\n",
        "make_dot(f)"
      ],
      "metadata": {
        "id": "UNVQ0rIkd0tu",
        "outputId": "e031fec7-1d3e-4a81-938e-eaa41814a92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-396059493241>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Diferencial usando torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Utiliza la funcion inversa para calcualr el valor del gradiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Imprimimos el valor de la derivada de \"y\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd a otro nivel\n",
        "\n",
        "Podemos definir vectores con ciertos valores y crear otros como resultado de operar los primeros y pytorch recordara el grafo de las computaciones.\n",
        "\n",
        "Supongamos que tenemos los valores:\n",
        "\n",
        "$ a = 1 $\n",
        "\n",
        "$ b = 2 $\n",
        "\n",
        "$ c = 0 $\n",
        "\n",
        "Y definimos $m$, $n$ (capas intermedias), $p$ (una prediccion) y $l$ (un costo) como:\n",
        "\n",
        "$ m = a + b $\n",
        "\n",
        "$ n = max(b,c) $\n",
        "\n",
        "$ p = m \\times n $\n",
        "\n",
        "$ l = p^2 $\n",
        "\n",
        "Pytorch calculara los valores intermedios dado el valor de las hojas:\n",
        "\n",
        "$ m = 3 $\n",
        "\n",
        "$ n = 2 $\n",
        "\n",
        "$ p = 6 $\n",
        "\n",
        "$ l = 36 $\n",
        "\n",
        "Y a la vez construira el siguiente grafo de computaciones (https://csacademy.com/app/graph_editor/)\n",
        "\n",
        "![Grafo](https://github.com/gforconi/UTNIA2025/blob/main/graph.png?raw=1)\n",
        "\n",
        "Entradas/Intermedio/Salida/Error\n",
        "\n",
        "Si $a$,$b$,$c$ son nuestros parametros y queremos minimizar el costo $l$. Querremos calcular: $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$\n",
        "\n",
        "A primera vista no es f谩cil calcular dichas derivadas. En general, usando la definici贸n de los valores, podemos calcular la derivada de un valor en funci贸n de los valores que dependen de forma directa de 茅l. Haciendo referencia al grafo de las computaciones (la imagen de arriba), podemos calcular el valor de $\\large\\frac{\\partial y}{\\partial x}$ si existe una arista que $x \\rightarrow y$. As铆, podemos calcular las siguientes derivadas, ya que cada variable depende de forma directa una de la otra:\n",
        "\n",
        "$\\large\\frac{\\partial l}{\\partial p} = 2 \\times p = 12$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial m} = n = 2$\n",
        "\n",
        "$\\large\\frac{\\partial p}{\\partial n} = m = 3$\n",
        "\n",
        "$\\large\\frac{\\partial m}{\\partial a} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial m}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial b} = 1$\n",
        "\n",
        "$\\large \\frac{\\partial n}{\\partial c} = 0$\n",
        "\n",
        "Pero como hacemos para calcular las derivadas $\\Large\\frac{\\partial l}{\\partial a}$, $\\Large\\frac{\\partial l}{\\partial b}$, $\\Large\\frac{\\partial l}{\\partial c}$ que son las que necesitamos para actualizar el gradiente?\n",
        "\n",
        "Centr茅mosnos por un momento en el caso de $\\Large\\frac{\\partial l}{\\partial a}$. Si bien no tenemos una f贸rmula que relacione de manera directa $a$ con $l$, el valor de $l$ depende del valor de $a$: esto es debido a que el valor de $l$ depende de $p$, que a su vez depende de $m$, que por 煤ltimo depende de $a$.\n",
        "\n",
        "Apliquemos la [regla de la cadena](https://en.wikipedia.org/wiki/Chain_rule) entre $p$ (que es una funci贸n de $a$), $l$ (que es funci贸n de $p$) y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a}$\n",
        "\n",
        "Mirando el t茅rmino de la derecha:\n",
        "- $\\Large \\frac{\\partial l}{\\partial p}$ lo conocemos y vale $12$.\n",
        "- $\\Large \\frac{\\partial p}{\\partial a}$ no lo hemos calculado a煤n, pero nos hemos \"acercado\" a $a$ en el grafo de las computaciones. Todo indica que si aplicamos una vez m谩s la regla de la cadena terminaremos llegando a $a$. Apliquemos pues, la regla de la cadena sobre $m$, $p$ y $a$:\n",
        "\n",
        "$\\Large\\frac{\\partial p}{\\partial a} = \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a}$\n",
        "\n",
        "Ahora, mirando el t茅rmino de la derecha, tenemos todos los valores: $\\Large \\frac{\\partial p}{\\partial m}$ vale 2 y $\\Large \\frac{\\partial m}{\\partial a}$ vale 1.\n",
        "\n",
        "Ya estamos en condiciones pues de calcular $\\Large\\frac{\\partial l}{\\partial a}$:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial a} = 12 \\times \\frac{\\partial p}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 12 \\times 2 \\times 1 = 24$\n",
        "\n",
        "Ordenando nuestro razonamiento, lo que estamos haciendo es calcular los gradientes respecto de las variables que est谩n m谩s cerca del resultado:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial m} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial m} = 12 \\times 2 = 24$\n",
        "\n",
        "\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial n} = \\frac{\\partial l}{\\partial p} \\times \\frac{\\partial p}{\\partial n} = 12 \\times 3 = 36$\n",
        "\n",
        "Y luego utilizar dichos gradientes para calcular los de las capas anteriores:\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial a} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial a} = 24 \\times 1 = 24$\n",
        "\n",
        "\n",
        "Podemos hacer lo mismo para calcular $\\Large\\frac{\\partial l}{\\partial c}$.\n",
        "\n",
        "\n",
        "Para el caso de $b$ usamos la [regla de la cadena multivariada](https://math.hmc.edu/calculus/hmc-mathematics-calculus-online-tutorials/multivariable-calculus/multi-variable-chain-rule/) (es muy parecida a la regla del producto, de hecho la regla del producto es un caso particular de la regla de la cadena multivariada). Esta aplica porque $b$ es usada en varios valores ($m$ y $n$) de los cuales depende en 煤ltima instancia el valor que queremos diferenciar $l$.\n",
        "\n",
        "$\\Large\\frac{\\partial l}{\\partial b} = \\frac{\\partial l}{\\partial m} \\times \\frac{\\partial m}{\\partial b} + \\frac{\\partial l}{\\partial n} \\times \\frac{\\partial n}{\\partial b} = 24+36 = 60$\n"
      ],
      "metadata": {
        "id": "k-OJkc4Hc1xU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a calcular los gradientes usando [Pytorch Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) (diferenciaci贸n autom谩tica).\n",
        "\n",
        "Primero definimos los valores hoja (de los que depende el resto). Ser铆an nuestro par谩metros (respecto de los cuales vamos a derivar despu茅s). Es importante el argumento requires_grad para que Pytorch sepa que tiene que calcular el grafo de las computaciones que le apliquemos a dichas variables, porque vamos a querer el gradiente respecto a dichas variables:"
      ],
      "metadata": {
        "id": "i0wfTsC6dsyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.],requires_grad=True)\n",
        "b = torch.tensor([2.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "a,b,c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mczHZe7Ldv4o",
        "outputId": "96f53f22-870b-4521-e3de-0a6f47790aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.], requires_grad=True),\n",
              " tensor([2.], requires_grad=True),\n",
              " tensor([0.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos definir otros valores en relaci贸n a los anteriores. En grad_fn lo que vemos es que Pytorch est谩 llevando un historial de como dichos valores fueron contru铆dos. Esto es el grafo de las computaciones que luego le servir谩 para calcular el gradiente:"
      ],
      "metadata": {
        "id": "YiHGlJNad58k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = a+b\n",
        "n = torch.max(a,b)\n",
        "m, n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dl1lCdKd7vi",
        "outputId": "45c927a5-e650-41e8-b586-a49e9cbbe52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.], grad_fn=<AddBackward0>),\n",
              " tensor([2.], grad_fn=<MaximumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = m*n\n",
        "l = p**2\n",
        "p, l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VxG8GBwd9kE",
        "outputId": "3d8e93e8-045b-4269-f70c-c27ba91ef69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6.], grad_fn=<MulBackward0>), tensor([36.], grad_fn=<PowBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular el gradiente de $l$ basta con llamar l.backwards()\n",
        "\n",
        "Generalmente s贸lo usamos los gradientes respecto a los par谩metros (las hojas). Si bien Pytorch calcula los gradientes respecto a los nodos intermedios (es un resultado parcial que luego ayudar谩 para calcular los gradientes en las hojas), los borra autom谩ticamente luego de usarlos para ahorrar memoria. Esto se puede evitar con el m茅todo .retain_grad(). En este caso le pediremos a Pytorch que no los borre ya que los queremos mostrar para corroborar que nos dio el mismo resultado que el que hallamos de manera anal铆tica:"
      ],
      "metadata": {
        "id": "weK2QLGeeDf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.retain_grad()\n",
        "n.retain_grad()\n",
        "p.retain_grad()\n",
        "l.retain_grad()\n",
        "\n",
        "l.backward()"
      ],
      "metadata": {
        "id": "2i1m0N0deHEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por 煤ltimo mostramos los gradientes de $l$ respecto a cada una de las variables. Podemos corroborar que los valores son los mismo que los hallados de manera anal铆tica arriba:"
      ],
      "metadata": {
        "id": "jLunGkFfeLYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l.grad, p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToB28OfAeKzx",
        "outputId": "f54d6a9b-0631-4bf7-ff94-e93157e4210f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.]), tensor([12.]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.grad, n.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoNqf-E9eQTS",
        "outputId": "55ea56ab-f2e0-43ff-8d31-8d32d694a4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([36.]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad, b.grad, c.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJX8vUryeSpG",
        "outputId": "1e81b83c-ab24-4ca8-f535-86c3af8baf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([24.]), tensor([60.]), None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretaci贸n del gradiente\n",
        "\n",
        "Recordar que el gradiente $\\Large \\frac{\\partial l}{\\partial a}$ indica cu谩nto cambia $l$ ante peque帽os cambios de $a$:\n",
        "\n",
        "$\\Large \\frac{\\partial l}{\\partial a} = lim_{\\Delta a \\rightarrow 0} \\frac{\\Delta l}{\\Delta a}$\n",
        "\n",
        "Corroboraremos esto emp铆ricamente, calculando $\\Delta l$ para variaciones $\\Delta a$, $\\Delta b$, $\\Delta c$ muy peque帽as.\n",
        "\n",
        "Para ellos haremos una funci贸n que nos calcule $l$ dado $a$, $b$ y $c$"
      ],
      "metadata": {
        "id": "-9gc_JnSeVxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_l(a,b,c):\n",
        "    m = a+b\n",
        "    n = torch.max(a,b)\n",
        "    p = m*n\n",
        "    l = p**2\n",
        "    return l"
      ],
      "metadata": {
        "id": "w5AczIuKej94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chequeamos que el resultado es efectivamente **36**\n"
      ],
      "metadata": {
        "id": "OqiOM4eSeq-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ov = calculate_l(a, b, c)\n",
        "ov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--U3tIQFeqlT",
        "outputId": "befac02c-0952-4b8f-db1d-047e0d90ce61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36.], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego calcularemos $l$ introduciendo un peque帽o cambio en $a$. Observaremos como resulta el ratio de cambio $\\Large \\frac{\\Delta l}{\\Delta a}$"
      ],
      "metadata": {
        "id": "cYvMsWcfewXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_change = 0.001\n",
        "nv = calculate_l(a + small_change, b, c)\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daLoA4KUe0Vx",
        "outputId": "3e627af7-2250-429b-e3d9-7595022332ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.02400207519531\n",
            "Change value: 0.0240020751953125\n",
            "Change ration: 24.002073287963867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente el ratio de variaci贸n es 24, como la derivada $\\Large \\frac{\\partial l}{\\partial a}$.\n",
        "Haremos lo mismo para $b$ y para $c$:"
      ],
      "metadata": {
        "id": "9M1__4HOe7dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b + small_change, c)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg2U1zuVe7OG",
        "outputId": "ae85fea6-835b-4fc9-fe75-3f1fffdf04ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.06003189086914\n",
            "Change value: 0.060031890869140625\n",
            "Change ration: 60.03188705444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nv = calculate_l(a , b, c + small_change)\n",
        "nv, (nv - ov) / small_change\n",
        "print(f'New value: {(nv).item()}')\n",
        "print(f'Change value: {(nv - ov).item()}')\n",
        "print(f'Change ration: {((nv - ov) / small_change).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybgnYitfFRt",
        "outputId": "2c372692-a068-432b-a881-a76064982689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New value: 36.0\n",
            "Change value: 0.0\n",
            "Change ration: 0.0\n"
          ]
        }
      ]
    }
  ]
}